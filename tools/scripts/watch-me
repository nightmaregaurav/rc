#!/usr/bin/env -S uv run --script

# /// script
# requires-python = "==3.13"
# dependencies = [
#   "fastapi",
#   "uvicorn",
#   "opencv-python",
#   "mss",
#   "numpy",
#   "sounddevice",
#   "pyautogui",
# ]
# ///

import argparse
import time
import threading
import queue

import cv2
import numpy as np
import mss
import sounddevice as sd
import pyautogui

from fastapi import FastAPI
from fastapi.responses import StreamingResponse
import uvicorn


# ============================================================
# Global state
# ============================================================

app = FastAPI()

stop_event = threading.Event()

video_streams: dict[str, "FrameBroadcaster"] = {}
audio_streams: dict[str, "AudioBroadcaster"] = {}


# ============================================================
# Broadcasters
# ============================================================

class FrameBroadcaster:
    def __init__(self):
        self.clients: set[queue.Queue[bytes]] = set()
        self.lock = threading.Lock()

    def register(self) -> queue.Queue[bytes]:
        q = queue.Queue(maxsize=2)
        with self.lock:
            self.clients.add(q)
        return q

    def unregister(self, q: queue.Queue[bytes]):
        with self.lock:
            self.clients.discard(q)

    def broadcast(self, frame: bytes):
        with self.lock:
            for q in list(self.clients):
                if not q.full():
                    q.put_nowait(frame)


class AudioBroadcaster:
    def __init__(self):
        self.clients: set[queue.Queue[bytes]] = set()
        self.lock = threading.Lock()

    def register(self) -> queue.Queue[bytes]:
        q = queue.Queue(maxsize=10)
        with self.lock:
            self.clients.add(q)
        return q

    def unregister(self, q: queue.Queue[bytes]):
        with self.lock:
            self.clients.discard(q)

    def broadcast(self, chunk: bytes):
        with self.lock:
            for q in list(self.clients):
                if not q.full():
                    q.put_nowait(chunk)


# ============================================================
# Cursor overlay
# ============================================================

def draw_cursor(frame: np.ndarray, monitor: dict) -> np.ndarray:
    x, y = pyautogui.position()

    mx = monitor["left"]
    my = monitor["top"]
    mw = monitor["width"]
    mh = monitor["height"]

    if not (mx <= x < mx + mw and my <= y < my + mh):
        return frame

    cx = int(x - mx)
    cy = int(y - my)

    color = (0, 0, 255)
    size = 10
    thickness = 2

    cv2.line(frame, (cx - size, cy), (cx + size, cy), color, thickness)
    cv2.line(frame, (cx, cy - size), (cx, cy + size), color, thickness)

    return frame


# ============================================================
# Capture loops
# ============================================================

def screen_capture_loop(monitor: dict, broadcaster: FrameBroadcaster):
    with mss.mss() as sct:
        while not stop_event.is_set():
            img = np.array(sct.grab(monitor))
            frame = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)

            frame = draw_cursor(frame, monitor)

            _, jpg = cv2.imencode(".jpg", frame)
            payload = (
                    b"--frame\r\n"
                    b"Content-Type: image/jpeg\r\n\r\n"
                    + jpg.tobytes()
                    + b"\r\n"
            )
            broadcaster.broadcast(payload)


def camera_capture_loop(camera_index: int, broadcaster: FrameBroadcaster):
    cap = cv2.VideoCapture(camera_index)
    if not cap.isOpened():
        return

    try:
        while not stop_event.is_set():
            ok, frame = cap.read()
            if not ok:
                break

            _, jpg = cv2.imencode(".jpg", frame)
            payload = (
                    b"--frame\r\n"
                    b"Content-Type: image/jpeg\r\n\r\n"
                    + jpg.tobytes()
                    + b"\r\n"
            )
            broadcaster.broadcast(payload)
    finally:
        cap.release()


def audio_capture_loop(device_index: int | None, broadcaster: AudioBroadcaster):
    def callback(indata, frames, time_info, status):
        broadcaster.broadcast(indata.tobytes())

    with sd.InputStream(
            device=device_index,
            samplerate=44100,
            channels=1,
            callback=callback,
    ):
        while not stop_event.is_set():
            time.sleep(0.1)


# ============================================================
# Client generators
# ============================================================

def mjpeg_client(broadcaster: FrameBroadcaster):
    q = broadcaster.register()
    try:
        while not stop_event.is_set():
            yield q.get()
    finally:
        broadcaster.unregister(q)


def audio_client(broadcaster: AudioBroadcaster):
    q = broadcaster.register()
    try:
        while not stop_event.is_set():
            yield q.get()
    finally:
        broadcaster.unregister(q)


# ============================================================
# API routes
# ============================================================

@app.get("/video/{stream_id}")
def video_feed(stream_id: str):
    broadcaster = video_streams.get(stream_id)
    if not broadcaster:
        return {"error": "video stream not found"}

    return StreamingResponse(
        mjpeg_client(broadcaster),
        media_type="multipart/x-mixed-replace; boundary=frame",
    )


@app.get("/audio/{stream_id}")
def audio_feed(stream_id: str):
    broadcaster = audio_streams.get(stream_id)
    if not broadcaster:
        return {"error": "audio stream not found"}

    return StreamingResponse(
        audio_client(broadcaster),
        media_type="application/octet-stream",
    )


# ============================================================
# Discovery helpers
# ============================================================

def discover_cameras(max_devices: int = 10) -> list[int]:
    cameras = []
    for i in range(max_devices):
        cap = cv2.VideoCapture(i)
        if cap.isOpened():
            cameras.append(i)
            cap.release()
    return cameras


def discover_screens() -> list[dict]:
    with mss.mss() as sct:
        return sct.monitors[1:]


def find_loopback_device() -> int | None:
    for idx, dev in enumerate(sd.query_devices()):
        name = dev["name"].lower()
        if "loopback" in name or "monitor" in name:
            return idx
    return None


# ============================================================
# Main
# ============================================================

def main():
    parser = argparse.ArgumentParser(
        description="Watch-me: stream screens, cameras, mic, speaker, with cursor",
    )

    parser.add_argument("-s", "--screen", action="store_true")
    parser.add_argument("-c", "--camera", action="store_true")
    parser.add_argument("-m", "--mic", action="store_true")
    parser.add_argument("-p", "--speaker", action="store_true")

    args = parser.parse_args()

    if not any(vars(args).values()):
        args.screen = True

    # Screens
    if args.screen:
        for i, monitor in enumerate(discover_screens()):
            stream_id = f"screen-{i}"
            broadcaster = FrameBroadcaster()
            video_streams[stream_id] = broadcaster

            threading.Thread(
                target=screen_capture_loop,
                args=(monitor, broadcaster),
                daemon=True,
            ).start()

            print(f"Screen {i}:  http://localhost:8000/video/{stream_id}")

    # Cameras
    if args.camera:
        for cam in discover_cameras():
            stream_id = f"camera-{cam}"
            broadcaster = FrameBroadcaster()
            video_streams[stream_id] = broadcaster

            threading.Thread(
                target=camera_capture_loop,
                args=(cam, broadcaster),
                daemon=True,
            ).start()

            print(f"Camera {cam}: http://localhost:8000/video/{stream_id}")

    # Mic
    if args.mic:
        broadcaster = AudioBroadcaster()
        audio_streams["mic"] = broadcaster

        threading.Thread(
            target=audio_capture_loop,
            args=(None, broadcaster),
            daemon=True,
        ).start()

        print("Mic audio:   http://localhost:8000/audio/mic")

    # Speaker
    if args.speaker:
        loopback = find_loopback_device()
        if loopback is not None:
            broadcaster = AudioBroadcaster()
            audio_streams["speaker"] = broadcaster

            threading.Thread(
                target=audio_capture_loop,
                args=(loopback, broadcaster),
                daemon=True,
            ).start()

            print("Speaker audio: http://localhost:8000/audio/speaker")
        else:
            print("Warning: no loopback device found for speaker capture")

    print("\nServer running at http://localhost:8000\n")

    try:
        uvicorn.run(app, host="0.0.0.0", port=8000)
    finally:
        stop_event.set()


if __name__ == "__main__":
    main()

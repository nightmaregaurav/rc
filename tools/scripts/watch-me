#!/usr/bin/env -S uv run --script

# /// script
# requires-python = "==3.13"
# dependencies = [
#     "argcomplete",
#     "fastapi",
#     "uvicorn",
#     "opencv-python",
#     "mss",
#     "numpy",
#     "sounddevice",
#     "pyautogui",
#     "aiortc",
#     "av",
# ]
# ///

import argparse
import asyncio
import queue
from contextlib import asynccontextmanager
import argcomplete
import threading
import uvicorn
import cv2
import mss
from fractions import Fraction
from typing import Dict
import numpy as np
import pyautogui
import sounddevice as sd
from fastapi import FastAPI, Request
from fastapi.responses import HTMLResponse
from aiortc import (
    RTCPeerConnection,
    RTCSessionDescription,
    VideoStreamTrack,
    AudioStreamTrack,
)
from av import VideoFrame, AudioFrame


# ============================================================
# Configuration
# ============================================================

CONFIG = {
    "DISPLAY_FPS": 15,
    "CAMERA_FPS": 30,
    "MAX_CAMERA_DEVICES_TO_TRY": 10,
    "AUDIO_SAMPLE_RATE": 44100,
    "AUDIO_CHANNELS": 1,
    "AUDIO_BLOCK_SIZE": 960
}


# ============================================================
# Global States
# ============================================================

cancellation_token = threading.Event()
video_tracks: Dict[str, VideoStreamTrack] = {}
audio_tracks: Dict[str, AudioStreamTrack] = {}


# ============================================================
# Helpers
# ============================================================

__MSS = None
def get_mss():
    global __MSS
    if __MSS is None:
        __MSS = mss.mss()
    return __MSS


def get_displays():
    return get_mss().monitors[1:]


def get_cameras():
    cameras = []
    for index in range(CONFIG["MAX_CAMERA_DEVICES_TO_TRY"]):
        cap = cv2.VideoCapture(index)
        if cap.isOpened():
            cameras.append(index)
            cap.release()
    return cameras


def get_microphones():
    microphones = []
    for device in sd.query_devices():
        if device["max_input_channels"] > 0:
            microphones.append(device)
    return microphones


def get_loopback_device():
    for device in sd.query_devices():
        if "loopback" in device["name"].lower() or "monitor" in device["name"].lower():
            return device
    return None


def draw_mouse_pointer(frame: np.ndarray, monitor: dict):
    x, y = pyautogui.position()
    mx, my = monitor["left"], monitor["top"]
    if mx <= x < mx + monitor["width"]:
        cv2.drawMarker(
            frame,
            (int(x - mx), int(y - my)),
            (0, 0, 255),
            cv2.MARKER_CROSS,
            20,
            2,
        )
    return frame


def format_defaults(cfg: dict) -> str:
    return ", ".join(f"{k}={v}" for k, v in cfg.items())


def config_completer(prefix, _, **__):
    if "=" in prefix:
        key, _, value_prefix = prefix.partition("=")

        if key not in CONFIG:
            return []

        default = str(CONFIG[key])
        if default.startswith(value_prefix):
            return [f"{key}={default}"]

        return []

    return [f"{key}=" for key in CONFIG if key.startswith(prefix)]


# ============================================================
# Track Producers
# ============================================================

class DisplayProducer:
    def __init__(self, device):
        self.device = device
        self.buffer = None

    async def start(self):
        while not cancellation_token.is_set():
            self.buffer = draw_mouse_pointer(
                cv2.cvtColor(
                    np.array(get_mss().grab(self.device)),
                    cv2.COLOR_BGRA2BGR
                ),
                self.device
            )
            await asyncio.sleep(1 / CONFIG["DISPLAY_FPS"])


class CameraProducer:
    def __init__(self, device_index: int):
        self.device = cv2.VideoCapture(device_index)
        self.buffer = None

    async def start(self):
        while not cancellation_token.is_set():
            ok, frame = self.device.read()
            if ok:
                self.buffer = frame
            await asyncio.sleep(1 / CONFIG["CAMERA_FPS"])


class AudioProducer:
    def __init__(self, device):
        self.device = device
        self.stream = None
        self.buffer = queue.Queue()

    async def start(self):
        def callback(indata, _, __, ___):
            if cancellation_token.is_set():
                raise sd.CallbackStop()

            pcm = np.clip(indata, -1.0, 1.0)
            pcm = (pcm * 32767).astype(np.int16)
            pcm = pcm.T

            self.buffer.put(pcm)

        try:
            self.stream = sd.InputStream(
                device=self.device["index"] if self.device is not None else None,
                samplerate=int(self.device["default_samplerate"]) if self.device else CONFIG["AUDIO_SAMPLE_RATE"],
                channels=CONFIG["AUDIO_CHANNELS"],
                blocksize=CONFIG["AUDIO_BLOCK_SIZE"],
                dtype="float32",
                callback=callback,
            )
            self.stream.start()
        except sd.PortAudioError as e:
            print(f"[audio] Skipping device '{self.device['name']}': {e}")


# ============================================================
# Tracks
# ============================================================

class VideoTrack(VideoStreamTrack):
    def __init__(self, producer: DisplayProducer | CameraProducer):
        super().__init__()
        self.producer = producer

    async def recv(self):
        pts, time_base = await self.next_timestamp()
        video_frame = VideoFrame.from_ndarray(
            self.producer.buffer
            if self.producer.buffer is not None
            else np.zeros((720, 1280, 3), np.uint8),
            format="bgr24"
        )
        video_frame.pts = pts
        video_frame.time_base = time_base
        return video_frame


class AudioTrack(AudioStreamTrack):
    def __init__(self, producer: AudioProducer):
        super().__init__()
        self.producer = producer
        self.samples_sent = 0

    async def recv(self):
        pcm = self.producer.buffer.get()
        pcm = pcm if pcm is not None else np.zeros(
        (CONFIG["AUDIO_CHANNELS"], CONFIG["AUDIO_BLOCK_SIZE"]),
            dtype=np.int16,
        )
        frame = AudioFrame.from_ndarray(
            pcm,
            format="s16",
            layout="mono" if CONFIG["AUDIO_CHANNELS"] == 1 else "stereo"
        )
        frame.sample_rate = CONFIG["AUDIO_SAMPLE_RATE"]
        frame.pts = self.samples_sent
        frame.time_base = Fraction(1, CONFIG["AUDIO_SAMPLE_RATE"])
        self.samples_sent += pcm.shape[1]
        return frame


# ============================================================
# Main
# ============================================================

def main():
    parser = argparse.ArgumentParser(
        description="Monitors screens, cameras, speaker, and mic of the device and streams them.",
        formatter_class=argparse.RawTextHelpFormatter,
        add_help=False,
    )

    parser.add_argument("-h", "--help", action="help", help="Show help message and exit.")
    parser.add_argument("-d", "--display", action="store_true", help="Enable display capture")
    parser.add_argument("-c", "--camera", action="store_true", help="Enable camera capture")
    parser.add_argument("-m", "--mic", action="store_true", help="Enable microphone capture")
    parser.add_argument("-s", "--speaker", action="store_true", help="Enable speaker capture")
    parser.add_argument(
        "-f", "--flags",
        action="append",
        metavar="KEY=VALUE",
        help=(
            "Override configuration flags (can be repeated)\n"
            f"Defaults: {format_defaults(CONFIG)}"
        )
    ).completer = config_completer

    argcomplete.autocomplete(parser, always_complete_options=False)
    args = parser.parse_args()

    if args.flags:
        for item in args.flags:
            if "=" not in item:
                parser.error(f"Invalid --config format '{item}'. Use KEY=VALUE.")

            key, value = item.split("=", 1)

            if key.strip() not in CONFIG:
                parser.error(f"Invalid config key '{key}'.")

            try:
                CONFIG[key.strip()] = int(value.strip())
            except ValueError:
                parser.error(f"Value for '{key.strip()}' must be an integer.")


    if not any(vars(args).values()):
        args.display = True

    @asynccontextmanager
    async def lifespan(_: FastAPI):
        if args.display:
            for display_index, display_device in enumerate(get_displays()):
                track_id = f"display-{display_index}"
                display_producer = DisplayProducer(display_device)
                video_tracks[track_id] = VideoTrack(display_producer)
                asyncio.create_task(display_producer.start())
        if args.camera:
            for camera_index in get_cameras():
                track_id = f"camera-{camera_index}"
                camera_producer = CameraProducer(camera_index)
                video_tracks[track_id] = VideoTrack(camera_producer)
                asyncio.create_task(camera_producer.start())
        if args.mic:
            for audio_device in get_microphones():
                track_id = f"audio-{audio_device['name']}"
                audio_producer = AudioProducer(audio_device)
                audio_tracks[track_id] = AudioTrack(audio_producer)
                asyncio.create_task(audio_producer.start())
        if args.speaker:
            loopback_device = get_loopback_device()
            if loopback_device is not None:
                track_id = f"loopback-{loopback_device['name']}"
                audio_producer = AudioProducer(loopback_device)
                audio_tracks[track_id] = AudioTrack(audio_producer)
                asyncio.create_task(audio_producer.start())
        yield

    app = FastAPI(lifespan=lifespan)

    @app.get("/favicon.ico", include_in_schema=False)
    def favicon():
        return {}

    @app.get("/tracks")
    def tracks():
        return {
            "video": list(video_tracks.keys()),
            "audio": list(audio_tracks.keys()),
        }


    @app.post("/offer")
    async def offer(req: Request):
        data = await req.json()
        video_id = data["videoTrackId"]
        audio_id = data["audioTrackId"]
        remote_description = RTCSessionDescription(
            sdp=data["description"]["sdp"],
            type=data["description"]["type"],
        )

        pc = RTCPeerConnection()
        await pc.setRemoteDescription(remote_description)

        for t in pc.getTransceivers():
            if t.kind == "video" and video_id:
                t.sender.replaceTrack(video_tracks[video_id])
                t.direction = "sendonly"

            elif t.kind == "audio" and audio_id:
                t.sender.replaceTrack(audio_tracks[audio_id])
                t.direction = "sendonly"

        answer = await pc.createAnswer()
        await pc.setLocalDescription(answer)

        return {
            "description": pc.localDescription
        }


    @app.get("/", response_class=HTMLResponse)
    def home():
        return """
    <!DOCTYPE html>
    <html>
        <body style="margin: 0; padding: 0;">
            <div id="controls" style="height: 40px; padding: 10px; display: flex; flex-wrap: wrap; justify-content: center; align-items: anchor-center; gap: 10px;">
                Video: <select id="video"><option value="">-- None --</option></select>
                Audio: <select id="audio"><option value="">-- None --</option></select>
                <button onclick="start()">Start</button>
            </div>
            <div style="width=100dvw; margin: 0; padding: 0; align-items: center; display: flex; justify-content: center;">
                <video id="v" autoplay playsinline controls style="max-width: 90%; max-height: calc(100dvh - 60px);"></video>
            </div>
            <script>
                async function loadTracks() {
                  const response = await fetch("/tracks");
                  const tracks = await response.json();
                
                  for (const v of tracks.video) {
                    video.add(new Option(v, v));
                  }
                  for (const a of tracks.audio) {
                    audio.add(new Option(a, a));
                  }
                }
                
                async function start() {
                  const stream = new MediaStream();
                  v.srcObject = stream;
                  
                  const pc = new RTCPeerConnection();
                  pc.ontrack = e => {
                    stream.addTrack(e.track);
                  }
                
                  if(video.value !== ""){
                    pc.addTransceiver('video', { direction: 'recvonly' });
                  }
                  if(audio.value !== ""){
                    pc.addTransceiver('audio', { direction: 'recvonly' });
                  }
                
                  const offer = await pc.createOffer();
                  await pc.setLocalDescription(offer);
                
                  const res = await fetch("/offer", {
                    method: "POST",
                    headers: {"Content-Type": "application/json"},
                    body: JSON.stringify({
                      description: pc.localDescription,
                      videoTrackId: video.value,
                      audioTrackId: audio.value
                    })
                  });
                
                  const answer = await res.json();
                  await pc.setRemoteDescription(answer.description);
                }
                
                loadTracks();
            </script>
        </body>
    </html>
    """

    try:
        uvicorn.run(app, host="0.0.0.0", port=8000)
    finally:
        cancellation_token.set()


if __name__ == "__main__":
    main()